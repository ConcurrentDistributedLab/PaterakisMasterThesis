\chapter{Introduction}
\label{chapter:introduction}

Processing big collections of data series is of paramount importance 
for a wide spectrum of applications, across many domains, such as: operation health
monitoring in data centers, vehicles and manufacturing processes, internet of things data
analysis, environmental and climate monitoring, energy consumption analysis, decision taking
in financial markets, telecommunications traffic analysis, detection of medical and health problems,
improvement of web-search results, identification of pests invading agricultural crops,
etc.~\cite{DBLP:journals/sigmod/Palpanas15,DBLP:journals/dagstuhl-reports/BagnallCPZ19,Palpanas2019}.
In the heart of analyzing such collections 
lies the process of similarity search. 
Given a query series $Q$, {\em similarity search} 
returns a set of data series from the collection that have the closest 
distance to $Q$. Similarity search comes at considerable cost, 
due to very large size of data series collections and the
high dimensionality (i.e., length) of the data series that modern applications need to analyze. 
To address these challenges, current state-of-the-art data series 
indexes~\cite{DBLP:journals/pvldb/EchihabiZPB18,isax2plus,wang2013data,peng2018paris,parisplus,peng2020messi,PFP21-I,PFP21-II,hercules,dumpy}
are based on data series summarization. They develop a tree index containing
data series summaries used to prune the series collection in order to
restrict the execution of costly computations only to a small subset of it.

State-of-the-art data series indexes~\cite{DBLP:journals/pvldb/EchihabiZPB18,isaxfamily,peng2018paris,peng2020messi,PFP21-I,PFP21-II,hercules} 
exploit the parallelism supportedby modern multicore machines,  
but are largely lock-based to achieve synchronization. 
Using locks results in {\em blocking} implementations: if a thread that
holds a lock delays, other threads block, without making any progress,  
until the lock is released. Such thread delays  can degrade performance. 
Some applications (eg, operation health-monitoring in nuclear plants, or gravitational-wave
detection in astrophysics), are sensitive to delays, and would benefit from our approach.
Locks may also result in known problems, such as deadlock, priority inversion,
and lock convoying~\cite{F04}.

Lock-freedom~\cite{HS08} is a widely studied property when designing
concurrent trees~\cite{EFRB10,EFHR14,FR2018,ABF+22} and other data structures~\cite{F04,HS08,FKR18}. 
It avoids the use of locks, ensuring that the system, as a whole, 
makes progress, independently of delays (or failures) of threads. 
The relative performance of lock-free vs. lock-based algorithms depends on the setting:
when threads are pinned to distinct cores, algorithms using fine-grained locks do well. However, in
oversubscribed settings (more threads than cores), lock-based algorithms can suffer due to threads
getting de-scheduled while holding a lock. Lock-free algorithms address these issues, but may be
complicated and result in worse performance in settings with no delays/failures.
Designing lock-free data series indexes, which exhibit good performance, is
the focus of this thesis: we develop a lock-free data-series index, which always
produces the correct output, while maintaining the good performance of state-of-the-art
lock-based indexes.

\noindent{\bf Challenges.} 
To achieve lock-freedom, some form of helping is usually employed. 
That is, appropriate mechanisms are provided to make threads aware 
of the work that other threads perform, so that a thread may help others to
complete their work whenever needed. 
Unfortunately, conventional helping mechanisms are rather expensive and often
introduce high overheads~\cite{F04,HS08,7515610,Williams2012CCI}.
For this reason, the vast majority of the software stack is still based on locks. 
Ensuring lock-freedom while maintaining the good performance of 
existing data series indexes is a major challenge. 

State-of-the-art indexes are designed to (a) maintain some form of {\em data locality},
and (b) avoid synchronization as much as possible.
For instance, they often separate the data into {\em disjoint sets}, and have a
distinct thread manipulate the data of each set~\cite{parisplus,PFP21-I,PFP21-II}.
This processing pattern enables threads to work in parallel and independently from each other,
resulting in reduced synchronization and communication costs.  
These principles for reduced communication and synchronization are easily achieved when locks 
(or barriers) are utilized~\cite{peng2018paris,peng2020messi,PFP21-I,PFP21-II}.
However, the way helping works in conventional lock-free data structures is inherently
incompatible to these principles, thus making it challenging to implement helping on top
of such indexes without sacrificing them. Providing lock-freedom while maintaining load-balancing
among threads and ensuring good data pruning are further challenges to address. 

State-of-the-art data series indexes encompass several data processing phases, 
which often employ different data structures to accomplish their efficient processing. 
Coming up with lock-free versions of these data structures, while respecting
the communication and synchronization cost principles that govern existing 
indexes, is another major challenge to address.

In order to develop a generalized approach for supporting lock-freedom 
on top of data series indexes in a {\em systematic way}, we need to study
and understand the design decisions of state-of-the-art indexes and the performance
principles that govern them. Then, we need appropriate abstractions for the data series
processing stages and their properties, as well as a set of design principles that need
to be respected for efficiency. Accomplishing these goals leads to additional challenges. 

Existing indexes are designed primarily for static datasets, where all data is known in advance,
and updates are not a primary concern. However, many modern applications require the ability to
ingest new data continuously while ensuring that queries reflect the most recent updates.
This introduces significant challenges. For example, one of the most important challenges is
achieving efficient synchronization between threads that perform updates and threads that perform
queries, which now run concurrently. This synchronization should be achieved without sacrificing
the high performance of static indexes.


\noindent
{\bf Our approach.}
We introduce FreSh, a novel static lock-free data series index, and DFreSh, its dynamic
counterpart (i.e., a version of FreSh that handles dynamic data). These algorithms address
all the challenges mentioned above.
Our experimental analysis demonstrate that FreSh matches the performance of 
MESSI~\cite{PFP21-I}, the state-of-the-art concurrent data-series index, which is lock-based. 
This confirms the efficiency of the helping mechanism we employ in FreSh. In many cases, 
FreSh even outperforms MESSI by allowing for higher parallelism during the construction of the
tree index.
It's important to note that if threads crash, MESSI (and other lock-based approaches
~\cite{peng2018paris,PFP21-I,PFP21-II,hercules}) will not terminate, which is 
why we did not include MESSI in the experiments for this scenario. In contrast, 
FreSh always terminates successfully and correctly (even in the precessence of failures).

To achieve FreSh, we developed ReFreSh, a generic approach that can be applied to a
range of state-of-the-art blocking indexes to provide lock-freedom without 
incurring additional costs. 
%
ReFresh introduces the concept of {\em locality-aware lock-freedom} which encompasses
the properties of data locality, high parallelism, low synchronization cost,
and load balancing met in the designs of many existing parallel data series indexes.
None of the conventional lock-free techniques we are aware of has been designed with
the goal of respecting these properties. Indeed, our experiments show that such
conventional techniques result in significantly lower performance.

ReFresh respects the workload and data separation of the underlying data series index, 
in order to not hurt the degrees of parallelism and load balancing of the index.
Moreover, it provides a mechanism for threads to determine whether a specific part
of a workload has been processed, and help only whenever necessary.
Refresh introduces two modes of execution for each thread: 
(i) {\em expeditive} and (ii) {\em standard}.
%
A thread executing in {\em standard} mode may incur synchronization overhead,
as it needs to synchronize with helper threads; a thread executing in {expeditive}
mode executes a code that avoids synchronization altogether. 
A thread starts by processing its assigned workload in expeditive mode. 
Helping is performed only after a thread has finished processing its own workload.
Then, threads have to synchronize to execute on standard mode. 
This way, \Refresh\ maintains the synchronization and communication costs as low as
that of the underlying index.

Refresh can be applied (Chapter~\ref{chapter:Locality-aware}) on top of any locality-aware
algorithm to get a lock-free version of it. 
\Fresh\ (Chapter~\ref{chapter:FreSh}) follows the design decisions of locality-aware
iSAX-based indexes~\cite{isaxfamily,PFP21-I} (see Chapter~\ref{chapter:prelemenaries}).
However, to develop \Fresh, we had to replace all data structures 
of the original index~\cite{PFP21-I} with corresponding locality-aware lock-free versions;
we present lock-free implementations of several concurrent data structures, such as  
binary trees and priority queues (Chapter~\ref{chapter:FreSh}).
The proposed lock-free tree contains several new ideas. 
Previous solutions~\cite{EFRB10,DBLP:conf/podc/EllenFHR13,FR2018,NRM20} require that
when a key is inserted in a leaf $\mathit{\ell}$, 
$\mathit{\ell}$ is copied and updated locally, and then
replaced in the shared tree. This results in bad performance. 
Instead, we designed a novel algorithm for updating leaves, 
which provides enhanced parallelism compared to existing algorithms.
Another novelty, is the support of the new implementations for the expeditive and standard
execution modes, which was a challenge by itself, as synchronization is
needed to transfer from one mode to the other.
We believe that these implementations, as well as \Refresh, could be employed to get
highly-efficient lock-free versions of several other big data-processing solutions.

To be able to apply ReFresh in a systematic way throughout all processing stages of an
iSAX-based index, we introduce the abstraction of a {\em traverse object}
(Chapter~\ref{chapter:traverse-object}). The traverse object is an abstract data type that
leads to a generic methodology for designing an iSAX-based index in a modular way. It abstracts
the main processing pattern used during the operation of iSAX-based indexes.
Specifically, the iSAX-based index can be implemented via traverse object operations.
The introduction of the traverse object is one of the novelties of our work.

Many applications today require dynamicity, meaning that data arrives in a dynamic manner.
To meet the needs of such applications, we develop a dynamic version of FreSh called DFreSh,
where queries can be executed while data dynamically arrives in the index. We explore two dynamicity
models inspired by different research domains and analyze their performance characteristics across
various synthetic and real datasets.



\noindent{\bf Contributions.} 
Our contributions are summarized as follows.

\noindent{$\bullet$ We develop a theoretical framework 
for supporting lock-freedom in a systematic way on top of highly-efficient data series indexes.
In particular, we present \Refresh, a novel {\em generic approach} that can be applied on top of
any locality-aware data series algorithm to ensure lock-freedom.} 

\noindent{$\bullet$ Based on \Refresh, we develop \Fresh, the first {\em lock-free},
efficient iSAX-based data series index. To get \Fresh, we present new lock-free implementations
of several data structures which support the needed functionality.}

\noindent{$\bullet$ Our experiments, with large synthetic and real datasets, demonstrate 
that \Fresh\ performs as good as the state-of-the-art {\em blocking} index,
thus paying no penalty for providing lock-freedom (and in many cases achieves better performance). 
}

\noindent{$\bullet$ Experiments show that by providing lock-freedom without
jeopardizing locality-awareness, \Fresh\ outperforms by far several lock-free
baselines we have designed, based on conventional approaches for ensuring lock-freedom.
}

\noindent{$\bullet$ We present a theoretical framework, which introduces the traverse object,
and utilizes it to enable the development of locality-aware data series indexes in a modular way.
}

\noindent{$\bullet$ Building on FreSh and incorporating ideas from both the database and
concurrent computing domains, we designed and implemented two versions of DFreSh, each aligned
with each of these fields. DFreSh is the first lock-free data series index that supports dynamic
batch insertions while concurrently answering queries. It preserves the key innovations of FreSh
and maintains high performance similar to FreSh, despite its dynamic nature.
}

\section{Other Related Work}
Numerous tree-based techniques for efficient and scalable data series similarity search
have been proposed~\cite{DBLP:journals/pvldb/EchihabiZPB18, DBLP:journals/pvldb/EchihabiZPB19,
DBLP:conf/edbt/EchihabiZP21, DBLP:journals/pvldb/EchihabiPZ21},
including approximate~\cite{DBLP:journals/pvldb/AziziEP23, 
DBLP:journals/kais/LevchenkoKYAMPS21} and 
progressive~\cite{DBLP:conf/sigmod/GogolouTEBP20, DBLP:journals/tvcg/JoSF20,
DBLP:conf/sigmod/LiZAH20, DBLP:journals/vldb/EchihabiTGBP23} solutions.
Among these, iSAX-based indexes~\cite{isaxfamily} have proven to be particularly
competitive in terms of both index construction and query performance~\cite{DBLP:journals/pvldb/EchihabiZPB18,
DBLP:journals/pvldb/EchihabiZPB19, hercules, odyssey, dumpy}. These indexes also include
parallel and distributed solutions that leverage modern hardware (e.g., SIMD, multi-core,
multi-socket, GPU), such as ParIS+~\cite{parisplus}, MESSI~\cite{PFP21-I}, and SING~\cite{PFP21-II},
as well as distributed approaches like DPiSAX~\cite{dpisax, dpisaxjournal} and
Odyssey~\cite{odyssey}. A summary of how a conventional iSAX based index work is provided in 
Chapter~\ref{chapter:prelemenaries}.
 
The first lock-free concurrent search tree implementation was proposed in~\cite{EFRB10}.
Building on the ideas from that paper, we develop a baseline algorithm, which we discuss
and compare experimentally with \textit{FreSh} in Chapter~\ref{chapter:Evaluation}.
Several other non-blocking concurrent search trees have been introduced in the 
literature~\cite{BER14, HL16, ABF20, HJ12, NRM20, CNT14, BP12, EFHR14, FR2018, ABF+22}.
The key novelty of our tree implementation, presented in chapter~\ref{chapter:FreSh}, is its
ability to concurrently perform multiple insert operations in a lock-free manner to
update the array in a (fat) leaf. Additionally, it supports the expeditive-standard mode
of execution. These advancements result in improved parallelism and better performance.
Our approach focuses solely on the functionality required for implementing traversal objects,
whereas the aforementioned implementations support a variety of other features or are designed
for different contexts.
 
Concurrent priority queues have been explored in~\cite{AK15-I, RT21, WG15, SUNDELL2005609,
tamir_et_al, LJ13}, none of which are based on sorted arrays or support different
execution modes. In our baseline lock-free implementations, we use a skip-list-based
priority queue~\cite{LJ13}, which has been shown to perform well. However, our experiments
indicate that the priority queue design we implemented for \textit{FreSh} significantly
outperforms this approach (Chapter~\ref{chapter:Evaluation}).
 
Universal constructions~\cite{FK11spaa, FK12ppopp, FK14, FK17opodis, FK09, FK20,
FKK18, EF+16, FKK22} can provide wait-free or non-blocking concurrent versions of any
sequential data structure. However, due to their general nature, they are often less
efficient than implementations tailored to specific data structures. The algorithms
in~\cite{FK11spaa, FK14, FKK22} are highly efficient for small shared objects
(e.g., stacks and queues) but are not suitable for our application.
 
The concept of transforming algorithms to achieve different progress guarantees is not
new, as seen in~\cite{SP14, ELM05, GKK06}, though these transformations address different
problems. The technique used in \textit{FreSh}, called \textit{ReFreSh}  departs from all these
prior approaches.

The use of timestamps for handling dynamic data is common in data-based systems.
For example, Apache Kafka and Google Spanner employ such mechanisms.
The first approach we use for dynamicity is inspired by this timestamp model ~\cite{babcock2002}.
Additionally, we introduce a second approach to designing a dynamic index that is linearizable \cite{herlihyWingLinearizability},
 a widely used correctness condition in concurrent data structures.