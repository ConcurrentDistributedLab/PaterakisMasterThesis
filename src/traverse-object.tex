\chapter{Traverse Object}
\label{chapter:traverse-object}
\vspace{-0.5cm}

\section{Traverse Object}
In this section, we introduce the \textbf{traverse object}, an abstract data type
that enables a modular design for iSAX-based indexes. The processing pipeline of
an iSAX-based index consists of multiple stages, where each stage processes data
produced by the previous one. The first stage handles the original dataset, while
subsequent stages refine and structure the data progressively. This structured
processing inspired the definition of the \textbf{traverse object}, whose
sequential specification is given below.
% 
\begin{definition}
\label{def:traverse}
Let $U$ be a universe of elements. A \textbf{traverse object} $S$ stores elements
of $U$ (which may not be distinct) and supports the following operations:

\begin{itemize}
    \item \textit{Put}($S,e,\mathit{param}$): Adds an element $e \in U$ to $S$.
    The optional parameter $\mathit{param}$ allows implementations to pass
    additional arguments.
    
    \item \textit{Traverse}($S,f,\mathit{fparam},del$): Traverses $S$, applying
    the function $f$ with parameters $\mathit{fparam}$ to each element. If the
    $del$ flag is set, the elements are deleted from $S$ after being processed.
    The parameter $\mathit{fparam}$ serves the same purpose as in \textit{Put}.

    \item \textit{Clean}($S$): Resets $S$ to be the empty traverse
    object.
\end{itemize}
% 
A traverse object $S$ satisfies the \textbf{traversing property}:  
Each instance of \textit{Traverse} in a sequential execution applies $f$ at
least once to all distinct elements added to $S$ that have not been deleted
in a previous invocation of \textit{Traverse}.
\end{definition}

\subsection{Traverse Objects in iSAX-Based Indexing}

\begin{algorithm}[htbp]
    \footnotesize
    \vspace*{2mm}
    
    \begin{algorithmic}[1]
    
    \Procedure{InitializeSharedObjects}{}
        \State \BC $\gets$ initially contains all raw data series
        \State \TP, \PS, \RS $\gets$ initially empty
        \State $\mathit{BSF} \gets$ some initial value
    \EndProcedure
    
    \vspace*{1mm}
    \State{Code for thread $t_i$, $i \in \{0, \ldots, n-1\}$:}		
    \vspace*{1mm}

    \Procedure{\normalfont QueryAnswering(QuerySeriesSet $\mathit{SQ}$) \textbf{returns} int}{}

        \State \BC.\Traverse(\&BufferCreation(), $\mathit{BCParam}$, \False)
        \State \TP.\Traverse(\&TreePopulation(), $\mathit{TPParam}$, \False)
        \State \PS.\Traverse(\&Prunning(), $\mathit{PSParam}$, \False)
        \State \RS.\Traverse(\&Refinement(), $\mathit{RSParam}$, \True)
        \State \Return $\mathit{BSF}$
    \EndProcedure
    
    \vspace*{1mm}
    \Procedure{\BufferCreation(DataSeries $\mathit{ds}$)}{}
        \State iSAXSummary $\mathit{iSAX} \gets$ Calculate the iSAX summary for $\mathit{ds}$
        \State Index $\mathit{bind} \gets$ index to appropriate buffer based on $\mathit{iSAX}$
        \State \TP.\Put($\langle \mathit{iSAX}$, index of $\mathit{ds}$ $\rangle$, $\mathit{bind}$)
    \EndProcedure
    
    \vspace*{1mm}
    \Procedure{\TreePopulation(Summary $\mathit{iSAX}$, Index $\mathit{ind}$,
         Index $\mathit{bind}$, Boolean $\mathit{flag}$)}{}
        \State \PS.\Put($\langle \mathit{iSAX}$, $\mathit{ind} \rangle$, $\mathit{bind}$, $\mathit{flag}$)
    \EndProcedure
    
    \vspace*{1mm}
    \Procedure{\Prunning(DataSeries $Q$, DataSeriesSet $\mathit{E}$,  
     \Statex \normalfont Boolean $\mathit{flag}$) \textbf{returns} boolean}{}
            \State iSAXSummary $\mathit{iSAX} \gets$ Calculate the iSAX summary for $\mathit{E}$
            \State int $\mathit{lbDist} \gets$ lower bound distance between $\mathit{iSAX}$ and $Q$
            \If{$\mathit{lbDist} < \mathit{BSF}$}
                \State \RS.\Put($\langle \mathit{E, iSAX} \rangle$, $\mathit{flag}$)
                \Return \True
            \EndIf
            \Return \False
    \EndProcedure
    
    \vspace*{1mm}
    \Procedure{\Refinement(DataSeries $Q$, DataSeriesSet $E$, Summary $\mathit{iSAX}$,
     \normalfont Function *\UpdateBSF) \textbf{returns} Boolean}{}
        \State int $\mathit{lbDist}$, $\mathit{rDist}$
        \State $\mathit{lbDist} \gets$ lower bound distance between $\mathit{iSAX}$ and $Q$
        \If{$\mathit{lbDist} < \mathit{BSF}$}
            \ForAll{pair $\langle \mathit{iSAX_{ds}, ind_{ds}} \rangle$ in $E$}
                \State $\mathit{lbDist} \gets$ lower bound distance between $\mathit{iSAX_{ds}}$ and $Q$
                \If{$\mathit{lbDist} < \mathit{BSF}$}
                    \State $\mathit{rDist} \gets$ real distance between $\mathit{ds}$ and $Q$
                    \If{$\mathit{rDist} < \mathit{BSF}$}
                        \State *\UpdateBSF($\mathit{BSF},\mathit{rDist}$) \Comment{user-provided routine}
                    \EndIf
                \EndIf
            \EndFor
            \Return \True
        \Else
            \Return \False
        \EndIf
    \EndProcedure
    
    \end{algorithmic}
    
    \caption{Implementation of an iSAX-based index using the traverse objects \BC, \TP, \PS, \RS.}
    \label{alg:iSAXTraverse}
    \end{algorithm}
    
    

We use four instances of a traverse object to implement the four stages of an iSAX-based
index. We call BC, TP, PS, and RS, the traverse objects that implement the buffer 
creation,tree population, prunning, and refinement stages, respectively.
% 
The buffers creation stage uses an array RawData to store the raw data series, thus, the
elements of BC are stored in RawData. The tree population stage uses a set of arrays
(summarization buffers) where the pairs of iSAX summaries and pointers to data series
are initially stored. TP stores these pairs. The prunning stage employs a leaf-oriented
tree to store these pairs. Thus, PS organizes the pairs into as many sets as the leaf
nodes of the tree. Each set contains the pairs stored in each leaf. Finally, the
refinement stage uses priority queues to store those tree leaves containing candidate
series.
% 
Answering a query is now comprised of a sequence of four invocations of TRAVERSE on the
different traverse objects. Algorithm 1 provides pseudocode for the implementation of
an iSAX-based index using traverse objects.
 
\noindent{\bf Static case.}
A static data series index where no data arrive in the system after the creation of the
index is comprised of four stages which do not overlap with one another. This is
usually ensured with the use of synchronization barriers. In the scheme of Algorithm 1,
the barriers, if needed, (as well as multithreading processing) should be incorporated
in the implementation of PUT and TRAVERSE. Thus, a static iSAX-based
index satisfies the following property:
% 
\begin{definition}[\textbf{Non-Overlapping Property}]
    \label{def:non-overlapping}
    In every concurrent execution of the index, for every traverse object $S$, an
    instance of \textit{Traverse} on $S$ is performed only after all \textit{Put}
    operations that add distinct elements to $S$ have completed.
\end{definition}
% 
Assume that the non-overlapping property holds for BC, TP, PS, and RS and that RawData
initially stores all raw data series. The traversing property implies that the
\textit{\BufferCreation} function is invoked at least once for each data series ds in RawData, so
at least one appropriate pair is added for it in TP, i.e., the summarization buffers
are populated appropriately. By the non-overlapping and the traversing properties,
\textit{\BufferCreation} is invoked for all these pairs. Since \textit{\BufferCreation}
invokes \textit{\Put} on PS, it follows that at least one pair for each of the data series of the collection
is added in PS (i.e. in the tree index). By the traversing property, all elements of PS
are traversed and \textit{\Prunning} is called on them. Thus, all tree leaves that cannot be
pruned are added in RS. Note that \textit{\Traverse} on RS is invoked with the del flag being True.
This allows to use (one or more) priority queues for implementing RS, and to employ
\textit{\DeleteMin} to delete each traversed element during \textit{\Traverse}. \textit{\Refinement}
will be applied on every traversed element of RS. Therefore, those leaves that cannot be pruned
will be further processed by calculating real distances and for the data series they store,
and by updating BSF whenever needed. Implementations for \textit{\Put} and \textit{\Traverse} for BC, TP,
PS, and RS in FreSh are presented in Chapter~\ref{chapter:FreSh}.


\noindent{\bf Dynamic case.}    
In a dynamic environment, data arrives in batches, each with a unique ID. For every
batch, the same sequence of events as in an iSAX-based index is executed.
During the Index Construction phase, workers compute summaries for each data series and
place them into the appropriate summarization buffers. Each summarization buffer is a 
two-dimensional array, where the number of rows corresponds to the number of index workers,
ensuring that each worker has its own dedicated part in the summarization buffer.
% 
Once all summaries for a batch have been generated, workers begin inserting, into the iSAX 
tree, pairs of summaries and pointers to the positions of the corresponding data series.
% 
Since this process repeats for every batch, both the iSAX tree and the
summarization buffers must accommodate continuous growth. However, while the iSAX tree
must retain all data, the summarization buffers only store temporary information that
is not needed anymore after a batch is processed. To avoid unnecessary memory growth,
we do not expand the summarization buffers with each new batch that arrives.
Instead, we clear and reuse them for each batch, ensuring efficient memory utilization. 
% Since the sequence of events
% is implemented by the traverse objects \BC\ and \TP\ they must be reinitialized
% before processing a new batch.
\newline \noindent{\bf Reusing The Summarization Buffers.} 
During \TP, workers traverse the summarization buffers to build the iSAX tree.
Specifically, each worker acquires a summarization buffer and proceeds with
constructing a subtree of the iSAX tree. Since summarization buffers are reused
across batches, a worker must determine whether the data stored by other workers
is still valid or belongs to a previous batch that has not yet been cleared.
To distinguish which batch the data in a buffer belongs to at any given time, we
associate with each worker's part within a summarization buffer with a
sequence number, which stores the id of the batch.
The reinitialization of summarization buffers is performed by invoking the 
\textit{\TPCLEAN}.  
During this process, for each summarization buffer, each worker is responsible for:
\begin{enumerate} [noitemsep, topsep=3pt, partopsep=0pt, parsep=0pt]
    \item Resetting the size of his part to zero and.
    \item Updating the sequence number of his part to match the ID of the next batch.
\end{enumerate}

Our system is designed to be lock-free. Because of this it is ensured that when an index worker
reaches the \TP\ stage, it indicates that the \BC\ stage has been completed successfully and
that all data series for the current batch have been stored in the summarization buffers, even
if some workers are slow or have experienced failures.
% 
During the execution of TP, each worker first checks the size of its part.
If the size is zero indicating that no data has been inserted into the currently processing part,
the worker moves on to the next part in this buffer,
If the size is nonzero, meaning there is data in that part, the worker proceeds by
reading the sequence number. If the sequence number differs from the current batch ID,
it indicates that the data is obsolete.

For instance a worker with ID $1$ may read a nonzero size in the buffer part of a worker
that contains data from the batch $X$. It may then become slow. Meanwhile, the worker 
responsible for that part updates the size to zero and sets the sequence number to
the current batch ID. To avoid situations where worker $1$ wakes up, reads the sequence number
as the current batch ID and starts processing a batch with actual size zero, workers verify that
the values they have read are still the same. This is done by rereading them and checking whether
their values have changed. If this is the case, the worker skips the work it was supposed to do.

% 
In a dynamic setting, threads may concurrently execute two distinct phases of the index:
\textit{Index Construction} and \textit{Query Answering}. This overlap introduces challenges
in programming such a system, as batch insertions occur simultaneously with query processing. 
Because of this concurrent execution, the Non-Overlapping
Property~\ref{def:non-overlapping}, which holds in the static case, does not apply
in the dynamic setting. However, this property still applies separately to the two
phases, Index Construction and Query Answering, but not to the system as a whole.

In Algorithm~\ref{alg:DynamiciTraverseObject} we present 
\textit{Index Construction} and \textit{Query Answering} as two separate procedures that can
be executed concurrently by threads. 
\newline \noindent{\bf IndexCreation. }Each thread has a local counter called
called $currentBatch$ which tracks the batch the worker is currently processing.
If the Timestamp-based model (referred to as SystemTS) is used, the system assigns a
timestamp to the entire batch. The process then proceeds by executing the \Traverse methods 
of \BC\ and \TP\ with no overalap to insert the batch into the iSAX tree.
% 
As mentioned earlier, before moving to the next batch, the summarization buffers must
be cleared to ensure they are ready for reuse (line~\ref{alg:reuse}).
Finally, the algorithm calculates the time it took to insert the last batch
into the index. If this time is less than the configured $DELAY$ value set by the user,
the index workers will be delayed for the remaining time before processing the next batch.
% 
\newline \noindent{\bf QueryAnswering. } 
If the system follows the Timestamp-based model, it assigns a
timestamp to each query. If this timestamp is greater than or equal to the timestamp
of the ongoing batch, the query must wait for the batch to complete.
In contrast, if the system uses the Linearizability model,
queries are responsible for incrementing a global counter, $GlobalSeq$, which serves
as a shared sequence number for both the index construction and Query Answering workers.
This is achieved using a CAS (Compare-and-Swap) instruction, where query workers attempt
to update $GlobalSeq$ using their local counter, $localSeq$. The procedure then proceeds by
invoking first the \Traverse method of \PS\ and then the traverse method of \RS\. Finally,
it invokes the the Clean method of \RS to prepare the priority queues for the next query.
followed by clearing the buffers of the \RS\ object (line~\ref{alg:reuseRS}).

\begin{algorithm}[htbp]
    \footnotesize
    \vspace*{2mm}
    
    \begin{algorithmic}[1]
    
    \Procedure{InitializeSharedObjects}{}
        \State \BC $\gets$ initially contains all raw data series
        \State \TP, \PS, \RS $\gets$ initially empty
        \State $\mathit{BSF} \gets$ some initial value
        \State $\mathit{GlobalSeq} \gets 0$
    \EndProcedure
    
    \vspace*{1mm}
    \State{Code for thread $t_i$, $i \in \{0, \ldots, k-1\}$:}    
    \vspace*{1mm}
    
    \Procedure{IndexCreation(int $\mathit{TotalUpdates}$) \textbf{returns} int}{}  \label{alg:IndexCreation}
        \State int $\mathit{currentBatch} \gets 1$
        \While{$\mathit{currentBatch} < \mathit{TotalBatches}$}
            \If{$\mathit{model} == \mathit{Timestamps}$ }
                \State batchTS $\gets$ getTS()
            \EndIf
            \State \BC.\Traverse(\&BufferCreation(), $\mathit{BCParam}$, \False)
            \State \TP.\Traverse(\&TreePopulation(), $\mathit{TPParam}$, \False)
            \State \TP.\Clean() \label{alg:reuse}
            % \ForAll{summarization buffers that have data}
            %     \State ReuseBuffers($\mathit{summBuffer}, \mathit{currentBatch}$)
            % \EndFor
            \If{$\mathit{DELAY} >= \mathit{BatchProcessingTime}$}
                \State sleep($\mathit{DELAY}-\mathit{BatchProcessingTime}$)
            \EndIf
            \State $\mathit{currentBatch} \gets \mathit{currentBatch} + 1$
        \EndWhile
    \EndProcedure
    
    \vspace*{1mm}
    
    \Procedure{QueryAnswering(QuerySeriesSet $\mathit{SQ}$) \textbf{returns} int}{} \label{alg:QueryAnswering}
        \State int $\mathit{localTS} \gets 0$
        \While{$\mathit{!SQ.Empty}$}
            \If{$\mathit{model} == \mathit{Linearizable}$}
                \If{$\mathit{localSeq} == \mathit{GlobalSeq}$}
                    \State \CAS(\&GlobalSeq, localSeq, localSeq + 1)
                \EndIf
            \ElsIf{$\mathit{model} == \mathit{Timestamps}$}
                \State queryTS $\gets$ getTS()
                \While {$\mathit{queryTS} >= \mathit{batchTS}$}
                    \State backoff()
                \EndWhile
            \EndIf
            \State \PS.\Traverse(\&Pruning(), $\mathit{PSParam}$, \False)
            \State \RS.\Traverse(\&Refinement(), $\mathit{RSParam}$, \False)
            \State \RS.\Clean() \label{alg:reuseRS}
            % \ForAll{summarization buffers that have data}
            %     \State ReuseBuffers($\mathit{summBuffer}, \mathit{currentBatch}$)
            % \EndFor
            
            \If{$\mathit{model} == \mathit{Linearizable}$}
                \State $\mathit{localSeq} = \mathit{localSeq} + 1$            
            \EndIf
        \EndWhile
        \State \Return $\mathit{BSF}$
    \EndProcedure
    
    % \vspace*{1mm}
    % \Procedure{ReuseSumBuffers(SumBuff * $\mathit{currBuff}$, int $\mathit{currentBatch}$)}{} \label{alg:BufferReuse}

    %     \State $\mathit{currBuff->size[workerID]} \gets 0$
    %     \If{$\mathit{currBuff->seq[workerID]} < \mathit{currentBatch}$}
    %         \State $\mathit{currBuff->seq[workerID]} \gets \mathit{currentBatch}$
    %     \EndIf
    %     \State $\mathit{currBuff->seq[workerID]++}$
    % \EndProcedure
    
    \end{algorithmic}
    
    \caption{Implementation of a dynamic iSAX-based index using the traverse objects \BC, \TP.}
    \label{alg:DynamiciTraverseObject}
    \end{algorithm}
