\chapter{Traverse Object}
\label{chapter:traverse-object}

\section{Traverse Object}

In this section, we introduce the \textbf{traverse object}, an abstract data type
that enables a modular design for iSAX-based indexes. The processing pipeline of
an iSAX-based index consists of multiple stages, where each stage processes data
produced by the previous one. The first stage handles the original dataset, while
subsequent stages refine and structure the data progressively. This structured
processing inspired the definition of the \textbf{traverse object}, whose
sequential specification is given below.
% 
\begin{definition}
\label{def:traverse}
Let $U$ be a universe of elements. A \textbf{traverse object} $S$ stores elements
of $U$ (which may not be distinct) and supports the following operations:

\begin{itemize}
    \item \textit{Put}($S,e,\mathit{param}$): Adds an element $e \in U$ to $S$.
    The optional parameter $\mathit{param}$ allows implementations to pass
    additional arguments.
    
    \item \textit{Traverse}($S,f,\mathit{fparam},del$): Traverses $S$, applying
    the function $f$ with parameters $\mathit{fparam}$ to each element. If the
    $del$ flag is set, the elements are deleted from $S$ after being processed.
    The parameter $\mathit{fparam}$ serves the same purpose as in \textit{Put}.

    \item \textit{Clean}($S,\mathit{fparam},$): Resets $S$ to be the empty traverse
    object.
\end{itemize}
% 
A traverse object $S$ satisfies the \textbf{traversing property}:  
Each instance of \textit{Traverse} in a sequential execution applies $f$ at
least once to all distinct elements added to $S$ that have not been deleted
in a previous invocation of \textit{Traverse}.
\end{definition}

\subsection{Traverse Objects in iSAX-Based Indexing}

\begin{algorithm}[htbp]
    \footnotesize
    \vspace*{2mm}
    
    \begin{algorithmic}[1]
    
    \Procedure{InitializeSharedObjects}{}
        \State \BC $\gets$ initially contains all raw data series
        \State \TP, \PS, \RS $\gets$ initially empty
        \State $\mathit{BSF} \gets$ some initial value
    \EndProcedure
    
    \vspace*{1mm}
    \State{Code for thread $t_i$, $i \in \{0, \ldots, n-1\}$:}		
    \vspace*{1mm}

    \Procedure{\normalfont QueryAnswering(QuerySeriesSet $\mathit{SQ}$) \textbf{returns} int}{}

        \State \BC.\Traverse(\&BufferCreation(), $\mathit{BCParam}$, \False)
        \State \TP.\Traverse(\&TreePopulation(), $\mathit{TPParam}$, \False)
        \State \PS.\Traverse(\&Prunning(), $\mathit{PSParam}$, \False)
        \State \RS.\Traverse(\&Refinement(), $\mathit{RSParam}$, \True)
        \State \Return $\mathit{BSF}$
    \EndProcedure
    
    \vspace*{1mm}
    \Procedure{\BufferCreation(DataSeries $\mathit{ds}$)}{}
        \State iSAXSummary $\mathit{iSAX} \gets$ Calculate the iSAX summary for $\mathit{ds}$
        \State Index $\mathit{bind} \gets$ index to appropriate buffer based on $\mathit{iSAX}$
        \State \TP.\Put($\langle \mathit{iSAX}$, index of $\mathit{ds}$ $\rangle$, $\mathit{bind}$)
    \EndProcedure
    
    \vspace*{1mm}
    \Procedure{\TreePopulation(Summary $\mathit{iSAX}$, Index $\mathit{ind}$,
         Index $\mathit{bind}$, Boolean $\mathit{flag}$)}{}
        \State \PS.\Put($\langle \mathit{iSAX}$, $\mathit{ind} \rangle$, $\mathit{bind}$, $\mathit{flag}$)
    \EndProcedure
    
    \vspace*{1mm}
    \Procedure{\Prunning(DataSeries $Q$, DataSeriesSet $\mathit{E}$,  
     \Statex \normalfont Boolean $\mathit{flag}$) \textbf{returns} boolean}{}
            \State iSAXSummary $\mathit{iSAX} \gets$ Calculate the iSAX summary for $\mathit{E}$
            \State int $\mathit{lbDist} \gets$ lower bound distance between $\mathit{iSAX}$ and $Q$
            \If{$\mathit{lbDist} < \mathit{BSF}$}
                \State \RS.\Put($\langle \mathit{E, iSAX} \rangle$, $\mathit{flag}$)
                \Return \True
            \EndIf
            \Return \False
    \EndProcedure
    
    \vspace*{1mm}
    \Procedure{\Refinement(DataSeries $Q$, DataSeriesSet $E$, Summary $\mathit{iSAX}$,
     \normalfont Function *\UpdateBSF) \textbf{returns} Boolean}{}
        \State int $\mathit{lbDist}$, $\mathit{rDist}$
        \State $\mathit{lbDist} \gets$ lower bound distance between $\mathit{iSAX}$ and $Q$
        \If{$\mathit{lbDist} < \mathit{BSF}$}
            \ForAll{pair $\langle \mathit{iSAX_{ds}, ind_{ds}} \rangle$ in $E$}
                \State $\mathit{lbDist} \gets$ lower bound distance between $\mathit{iSAX_{ds}}$ and $Q$
                \If{$\mathit{lbDist} < \mathit{BSF}$}
                    \State $\mathit{rDist} \gets$ real distance between $\mathit{ds}$ and $Q$
                    \If{$\mathit{rDist} < \mathit{BSF}$}
                        \State *\UpdateBSF($\mathit{BSF},\mathit{rDist}$) \Comment{user-provided routine}
                    \EndIf
                \EndIf
            \EndFor
            \Return \True
        \Else
            \Return \False
        \EndIf
    \EndProcedure
    
    \end{algorithmic}
    
    \caption{Implementation of an iSAX-based index using the traverse objects \BC, \TP, \PS, \RS.}
    \label{alg:iSAXTraverse}
    \end{algorithm}
    
    

We use four instances of a traverse object to implement the four stages of an iSAX-based
index. We call BC, TP, PS, and RS, the traverse objects that implement the buffer 
creation,tree population, prunning, and refinement stages, respectively.
% 
The buffers creation phase uses an array RawData to store the raw data series, thus, the
elements of BC are stored in RawData. The tree population phase uses a set of arrays
(summarization buffers) where the pairs of iSAX summaries and pointers to data series
are initially stored. TP stores these pairs. The prunning stage employs a leaf-oriented
tree to store these pairs. Thus, PS organizes the pairs into as many sets as the leaf
nodes of the tree. Each set contains the pairs stored in each leaf. Finally, the
refinement stage uses priority queues to store those tree leaves containing candidate
series.
% 
Answering a query is now comprised of a sequence of four invocations of TRAVERSE on the
different traverse objects. Algorithm 1 provides pseudocode for the implementation of
an iSAX-based index using traverse objects.
 
\noindent{\bf Static case:}
A static data series index where no data arrive in the system after the creation of the
index is comprised of four stages which do not overlap with one another. This is
usually ensured with the use of synchronization barriers. In the scheme of Algorithm 1,
the barriers, if needed, (as well as multithreading processing) should be incorporated
in the implementation of PUT and TRAVERSE. Thus, a static iSAX-based
index satisfies the following property:
% 
\begin{definition}[\textbf{Non-Overlapping Property}]
    \label{def:non-overlapping}
    In every concurrent execution of the index, for every traverse object $S$, an
    instance of \textit{Traverse} on $S$ is performed only after all \textit{Put}
    operations that add distinct elements to $S$ have completed.
\end{definition}
% 
Assume that the non-overlapping property holds for BC, TP, PS, and RS and that RawData
initially stores all raw data series. The traversing property implies that the
BUFFERCREATION function is invoked at least once for each data series ds in RawData, so
at least one appropriate pair is added for it in TP, i.e., the summarization buffers
are populated appropriately. By the non-overlapping and the traversing properties,
TREEPOPULATION is invoked for all these pairs. Since TREEPOPULATION invokes PUT on PS,
it follows that at least one pair for each of the data series of the collection is
added in PS (i.e. in the tree index). By the traversing property, all elements of PS
are traversed and PRUNNING is called on them. Thus, all tree leaves that cannot be
pruned are added in RS. Note that TRAVERSE on RS is invoked with the del flag being True.
This allows to use (one or more) priority queues for implementing RS, and to employ
DELETEMIN to delete each traversed element during TRAVERSE. REFINEMENT will be applied
on every traversed element of RS. Therefore, those leaves that cannot be pruned will be
further processed by calculating real distances and for the data series they store,
and by updating BSF whenever needed. Implementations for PUT and TRAVERSE for BC, TP,
PS, and RS in FreSh are presented in chapter~\ref{chapter:FreSh}.

\bl{
\noindent{\bf Dynamic case:}    
In a dynamic environment, data arrives in batches, each with a unique ID. For every
batch, the same sequence of events in an iSAX-based index is executed.
During the Index Construction phase, workers compute summaries for each data series and
place them into the appropriate summarization buffer. Each summarization buffer is a 2D
array, where the number of rows corresponds to the number of index workers, ensuring
that each worker has its own dedicated memory.
Once all summaries for a batch have been generated, workers begin inserting pairs of
summaries and pointers to the positions of the corresponding data series into the iSAX
tree.  Since this process repeats for every batch, both the iSAX tree and the
summarization buffers must accommodate continuous growth. However, while the iSAX tree
must retain all data, the summarization buffers only store temporary information that
becomes irrelevant after a batch is processed. To avoid unnecessary memory growth,
we do not expand the summarization buffers indefinitely. Instead, we clear and reuse
them for each batch, ensuring efficient memory utilization. 
% Since the sequence of events
% is implemented by the traverse objects \BC\ and \TP\ they must be reinitialized
% before processing a new batch.
\noindent{\bf Summarization Buffers:} 
During \TP, workers traverse the summarization buffers to build the iSAX tree.
Specifically, each worker acquires a summarization buffer and proceeds with
constructing a subtree of the iSAX tree. Since summarization buffers are reused
across batches, a worker must determine whether the data stored by other workers
is still valid or belongs to a previous batch that has not yet been cleared.
To distinguish which batch the data in a buffer belongs to at any given time, we
decided to associate each worker's memory within a summarization buffer with a
sequence number, which stores the id of the batch.
The reinitialization of summarization buffers is performed by invoking the 
\textit{TRAVERSE} method of \TP\ with a clean function as a parameter.  
During this process, for each summarization buffer, each worker is responsible for:
1. Resetting the size of his part to zero and
2. Updating the sequence number of his part to match the ID of the next batch.
% 
Our system is designed to be lock-free. Thus, when an index worker reaches the \TP\
stage, it indicates that the \BC\ phase has been completed successfully and that all
data series for the current batch have been stored in the summarization buffers, even
if some workers are slow or have experienced failures.
% 
During the execution of \TP, each worker first checks the size of its part.
If the size is zero, the worker moves on to the next part, indicating that no data
has been inserted into this part during the current batch. If the size is non-zero,
meaning there is data in that part, the worker proceeds by reading the sequence number.
If the sequence number differs from the current batch ID, it indicates that the data
is obsolete.
% 
Since the system operates asynchronously, there can be stalls between these two reads.
For instance, a worker with ID 1 may read a non-zero size and then stall. Meanwhile,
the worker responsible for that part may update the size to 0 and set the sequence
number to the current batch ID. When worker 1 wakes up, it reads the sequence number
as the current batch ID. Clearly, this is an incorrect situation. To handle this,
workers must verify if the values they have read are still the same. If not, they
must re-read them to ensure consistency.
% 
In a dynamic setting, threads may concurrently execute two distinct phases of the index:
\textit{Index Creation} and \textit{Query Answering}. This overlap introduces challenges in programming
such a system, as batch insertions occur simultaneously with query processing. Our work
proposes two different models: the first restricts concurrency by requiring queries
to wait for the completion of a batch before including its data in their results,
ensuring that queries work only with data that is already indexed. The second model is
more dynamic, allowing queries to determine on the fly whether or not to include data
from ongoing batches in their responses. 
Because of this concurrent execution, the Non-Overlapping
Property~\ref{def:non-overlapping}, which holds in the static case, does not apply
in the dynamic setting. However, this property still applies separately to the two
major subtasks, Index Creation and Query Answering, but not to the system as a whole.
% 
In Algorithm~\ref{alg:DynamiciTraverseObject} we present 
\textit{Index Creation} and \textit{Query Answering} as two separate procedures that can
be executed concurrently by threads. In line~\ref{alg:IndexCreation} we show the
procedure responsible for Index Construction. Each thread has a local counter called
called $currentBatch$ which tracks the batch the worker is currently processing.
If the Timestamp-based model (referred to as SystemTS) is used, the system assigns a
timestamp to the entire batch. The process then proceeds by sequentially executing the
\BC\ and \TP\ traverse objects to insert the batch into the iSAX tree.
% 
As mentioned earlier, before moving to the next batch, the summarization buffers must
be cleared to ensure they are ready for reuse. This is shown in line~\ref{alg:reuse}.
Finally, the algorithm dynamically calculates the time it took to insert the last batch
into the index. If this time is less than the configured $DELAY$ value set by the user,
the index workers will sleep for the remaining time before processing the next batch.
% 
In line~\ref{alg:QueryAnswering}, we present the Query Answering procedure. For each
query, if the system follows the Timestamp-based model (SystemTS), it assigns a
timestamp to the query. If this timestamp is greater than or equal to the timestamp
of the ongoing batch, the query must wait for the batch to complete.
In contrast, if the system uses the Linearizable model (referred to as LogicalTS),
queries are responsible for incrementing a global counter, $GlobalSeq$, which serves
as a shared timestamp for both Index Creation and Query Answering. This is achieved
using a CAS (Compare-and-Swap) instruction, where query workers attempt to update
$GlobalSeq$ using their local counter, $localSeq$. The procedure then proceeds by
sequentially invoking the \PS\ and \RS\ traverse objects, followed by clearing the
buffers of the \RS\ object (line~\ref{alg:reuseRS}).

\begin{algorithm}[htbp]
    \footnotesize
    \vspace*{2mm}
    
    \begin{algorithmic}[1]
    
    \Procedure{InitializeSharedObjects}{}
        \State \BC $\gets$ initially contains all raw data series
        \State \TP, \PS, \RS $\gets$ initially empty
        \State $\mathit{BSF} \gets$ some initial value
        \State $\mathit{GlobalSeq} \gets 0$
    \EndProcedure
    
    \vspace*{1mm}
    \State{Code for thread $t_i$, $i \in \{0, \ldots, k-1\}$:}    
    \vspace*{1mm}
    
    \Procedure{IndexCreation(int $\mathit{TotalUpdates}$) \textbf{returns} int}{}  \label{alg:IndexCreation}
        \State int $\mathit{currentBatch} \gets 1$
        \While{$\mathit{currentBatch} < \mathit{TotalBatches}$}
            \If{$\mathit{model} == \mathit{SystemTS}$ }
                \State batchTS $\gets$ getTS()
            \EndIf
            \State \BC.\Traverse(\&BufferCreation(), $\mathit{BCParam}$, \False)
            \State \TP.\Traverse(\&TreePopulation(), $\mathit{TPParam}$, \False)
            \State \TP.\Clean($\mathit{NULL}$) \label{alg:reuse}
            % \ForAll{summarization buffers that have data}
            %     \State ReuseBuffers($\mathit{summBuffer}, \mathit{currentBatch}$)
            % \EndFor
            \If{$\mathit{DELAY} >= \mathit{BatchProcessingTime}$}
                \State sleep($\mathit{DELAY}-\mathit{BatchProcessingTime}$)
            \EndIf
            \State $\mathit{currentBatch} \gets \mathit{currentBatch} + 1$
        \EndWhile
    \EndProcedure
    
    \vspace*{1mm}
    
    \Procedure{QueryAnswering(QuerySeriesSet $\mathit{SQ}$) \textbf{returns} int}{} \label{alg:QueryAnswering}
        \State int $\mathit{localTS} \gets 0$
        \While{$\mathit{!SQ.Empty}$}
            \If{$\mathit{model} == \mathit{LogicalTS}$}
                \If{$\mathit{localSeq} == \mathit{GlobalSeq}$}
                    \State \CAS(\&GlobalSeq, localSeq, localSeq + 1)
                \EndIf
            \ElsIf{$\mathit{model} == \mathit{SystemTS}$}
                \State queryTS $\gets$ getTS()
                \While {$\mathit{queryTS} >= \mathit{batchTS}$}
                    \State backoff()
                \EndWhile
            \EndIf
            \State \PS.\Traverse(\&Pruning(), $\mathit{PSParam}$, \False)
            \State \RS.\Traverse(\&Refinement(), $\mathit{RSParam}$, \False)
            \State \RS.\Clean($\mathit{NULL}$) \label{alg:reuseRS}
            % \ForAll{summarization buffers that have data}
            %     \State ReuseBuffers($\mathit{summBuffer}, \mathit{currentBatch}$)
            % \EndFor
            
            \If{$\mathit{model} == \mathit{LogicalTS}$}
                \State $\mathit{localSeq} = \mathit{localSeq} + 1$            
            \EndIf
        \EndWhile
        \State \Return $\mathit{BSF}$
    \EndProcedure
    
    % \vspace*{1mm}
    % \Procedure{ReuseSumBuffers(SumBuff * $\mathit{currBuff}$, int $\mathit{currentBatch}$)}{} \label{alg:BufferReuse}

    %     \State $\mathit{currBuff->size[workerID]} \gets 0$
    %     \If{$\mathit{currBuff->seq[workerID]} < \mathit{currentBatch}$}
    %         \State $\mathit{currBuff->seq[workerID]} \gets \mathit{currentBatch}$
    %     \EndIf
    %     \State $\mathit{currBuff->seq[workerID]++}$
    % \EndProcedure
    
    \end{algorithmic}
    
    \caption{Implementation of a dynamic iSAX-based index using the traverse objects \BC, \TP.}
    \label{alg:DynamiciTraverseObject}
    \end{algorithm}
}